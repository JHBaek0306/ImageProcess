{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Average Error: 0.1265677260685768\n",
      "Epoch 100, Average Error: 0.1265613941866337\n",
      "Epoch 200, Average Error: 0.12655599078145963\n",
      "Epoch 300, Average Error: 0.12655062498369313\n",
      "Epoch 400, Average Error: 0.1265452969938144\n",
      "Epoch 500, Average Error: 0.12654000690016495\n",
      "Epoch 600, Average Error: 0.12653475477934703\n",
      "Epoch 700, Average Error: 0.12652954069799704\n",
      "Epoch 800, Average Error: 0.12652436471309808\n",
      "Epoch 900, Average Error: 0.12651922687221642\n",
      "Epoch 1000, Average Error: 0.12651412721367017\n",
      "Epoch 1100, Average Error: 0.12650906576662582\n",
      "Epoch 1200, Average Error: 0.12650404255112135\n",
      "Epoch 1300, Average Error: 0.12649905757801105\n",
      "Epoch 1400, Average Error: 0.12649411084883283\n",
      "Epoch 1500, Average Error: 0.12648920235559513\n",
      "Epoch 1600, Average Error: 0.12648433208048346\n",
      "Epoch 1700, Average Error: 0.12647949999548788\n",
      "Epoch 1800, Average Error: 0.12647470606195058\n",
      "Epoch 1900, Average Error: 0.1264699502300363\n",
      "Epoch 2000, Average Error: 0.1264652324381278\n",
      "Epoch 2100, Average Error: 0.1264605526121485\n",
      "Epoch 2200, Average Error: 0.12645591066481607\n",
      "Epoch 2300, Average Error: 0.1264513064948309\n",
      "Epoch 2400, Average Error: 0.1264467399860036\n",
      "Epoch 2500, Average Error: 0.12644221100632647\n",
      "Epoch 2600, Average Error: 0.12643771940699441\n",
      "Epoch 2700, Average Error: 0.12643326502138047\n",
      "Epoch 2800, Average Error: 0.12642884766397203\n",
      "Epoch 2900, Average Error: 0.12642446712927402\n",
      "Epoch 3000, Average Error: 0.12642012319068482\n",
      "Epoch 3100, Average Error: 0.12641581559935133\n",
      "Epoch 3200, Average Error: 0.1264115440830099\n",
      "Epoch 3300, Average Error: 0.12640730834481856\n",
      "Epoch 3400, Average Error: 0.12640310806218719\n",
      "Epoch 3500, Average Error: 0.12639894288561065\n",
      "Epoch 3600, Average Error: 0.12639481243751072\n",
      "Epoch 3700, Average Error: 0.12639071631109197\n",
      "Epoch 3800, Average Error: 0.1263866540692149\n",
      "Epoch 3900, Average Error: 0.12638262524329133\n",
      "Epoch 4000, Average Error: 0.1263786293322043\n",
      "Epoch 4100, Average Error: 0.12637466580125503\n",
      "Epoch 4200, Average Error: 0.12637073408113836\n",
      "Epoch 4300, Average Error: 0.12636683356694728\n",
      "Epoch 4400, Average Error: 0.12636296361720598\n",
      "Epoch 4500, Average Error: 0.1263591235529301\n",
      "Epoch 4600, Average Error: 0.12635531265671118\n",
      "Epoch 4700, Average Error: 0.12635153017182243\n",
      "Epoch 4800, Average Error: 0.12634777530134014\n",
      "Epoch 4900, Average Error: 0.12634404720727488\n",
      "Epoch 5000, Average Error: 0.12634034500970562\n",
      "Epoch 5100, Average Error: 0.1263366677859073\n",
      "Epoch 5200, Average Error: 0.126333014569463\n",
      "Epoch 5300, Average Error: 0.12632938434934854\n",
      "Epoch 5400, Average Error: 0.12632577606897755\n",
      "Epoch 5500, Average Error: 0.12632218862519295\n",
      "Epoch 5600, Average Error: 0.12631862086718926\n",
      "Epoch 5700, Average Error: 0.12631507159534985\n",
      "Epoch 5800, Average Error: 0.12631153955997954\n",
      "Epoch 5900, Average Error: 0.12630802345991424\n",
      "Epoch 6000, Average Error: 0.12630452194098576\n",
      "Epoch 6100, Average Error: 0.12630103359431852\n",
      "Epoch 6200, Average Error: 0.12629755695443443\n",
      "Epoch 6300, Average Error: 0.12629409049713844\n",
      "Epoch 6400, Average Error: 0.12629063263715756\n",
      "Epoch 6500, Average Error: 0.1262871817255013\n",
      "Epoch 6600, Average Error: 0.12628373604651177\n",
      "Epoch 6700, Average Error: 0.12628029381456785\n",
      "Epoch 6800, Average Error: 0.1262768531704044\n",
      "Epoch 6900, Average Error: 0.12627341217700622\n",
      "Epoch 7000, Average Error: 0.1262699688150309\n",
      "Epoch 7100, Average Error: 0.12626652097771193\n",
      "Epoch 7200, Average Error: 0.12626306646518978\n",
      "Epoch 7300, Average Error: 0.12625960297821073\n",
      "Epoch 7400, Average Error: 0.1262561281111314\n",
      "Epoch 7500, Average Error: 0.12625263934415737\n",
      "Epoch 7600, Average Error: 0.126249134034739\n",
      "Epoch 7700, Average Error: 0.12624560940803722\n",
      "Epoch 7800, Average Error: 0.12624206254636547\n",
      "Epoch 7900, Average Error: 0.12623849037749918\n",
      "Epoch 8000, Average Error: 0.12623488966173596\n",
      "Epoch 8100, Average Error: 0.12623125697757198\n",
      "Epoch 8200, Average Error: 0.12622758870584577\n",
      "Epoch 8300, Average Error: 0.12622388101218132\n",
      "Epoch 8400, Average Error: 0.12622012982754044\n",
      "Epoch 8500, Average Error: 0.1262163308266703\n",
      "Epoch 8600, Average Error: 0.1262124794042036\n",
      "Epoch 8700, Average Error: 0.1262085706481345\n",
      "Epoch 8800, Average Error: 0.1262045993103576\n",
      "Epoch 8900, Average Error: 0.12620055977391148\n",
      "Epoch 9000, Average Error: 0.12619644601651725\n",
      "Epoch 9100, Average Error: 0.12619225156994474\n",
      "Epoch 9200, Average Error: 0.1261879694746672\n",
      "Epoch 9300, Average Error: 0.1261835922291869\n",
      "Epoch 9400, Average Error: 0.12617911173331764\n",
      "Epoch 9500, Average Error: 0.12617451922460093\n",
      "Epoch 9600, Average Error: 0.12616980520690027\n",
      "Epoch 9700, Average Error: 0.1261649593700666\n",
      "Epoch 9800, Average Error: 0.12615997049938535\n",
      "Epoch 9900, Average Error: 0.12615482637329964\n",
      "\n",
      "예측 결과:\n",
      "입력: [0 0], 타겟: [0], 예측: [0.49590117]\n",
      "입력: [0 1], 타겟: [1], 예측: [0.50115149]\n",
      "입력: [1 0], 타겟: [1], 예측: [0.49885395]\n",
      "입력: [1 1], 타겟: [0], 예측: [0.50381186]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 활성화 함수 (시그모이드) 및 그 미분\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):\n",
    "        \"\"\"\n",
    "        MLP 초기화\n",
    "        :param input_size: 입력층 뉴런 수\n",
    "        :param hidden_size: 은닉층 뉴런 수\n",
    "        :param output_size: 출력층 뉴런 수\n",
    "        :param learning_rate: 학습률\n",
    "        \"\"\"\n",
    "        # 가중치 초기화 (u: 입력층 -> 은닉층, v: 은닉층 -> 출력층)\n",
    "        self.u = np.random.randn(input_size, hidden_size) * 0.01  # u 초기화\n",
    "        self.v = np.random.randn(hidden_size, output_size) * 0.01  # v 초기화\n",
    "        \n",
    "        # 바이어스 초기화\n",
    "        self.b_u = np.zeros((1, hidden_size))  # 은닉층 바이어스\n",
    "        self.b_v = np.zeros((1, output_size))  # 출력층 바이어스\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        순전파 (Forward Pass)\n",
    "        :param x: 입력 데이터 (1, input_size)\n",
    "        :return: 은닉층 출력 z, 최종 출력 o\n",
    "        \"\"\"\n",
    "        # 입력층 -> 은닉층\n",
    "        self.z_sum = np.dot(x, self.u) + self.b_u  # z_sum = x * u + b_u\n",
    "        self.z = sigmoid(self.z_sum)  # z = τ(z_sum)\n",
    "        \n",
    "        # 은닉층 -> 출력층\n",
    "        self.o_sum = np.dot(self.z, self.v) + self.b_v  # o_sum = z * v + b_v\n",
    "        self.o = sigmoid(self.o_sum)  # o = τ(o_sum)\n",
    "        \n",
    "        return self.z, self.o\n",
    "\n",
    "    def backward(self, x, t, z, o):\n",
    "        \"\"\"\n",
    "        역전파 (Backward Pass)\n",
    "        :param x: 입력 데이터\n",
    "        :param t: 타겟 값\n",
    "        :param z: 은닉층 출력\n",
    "        :param o: 최종 출력\n",
    "        \"\"\"\n",
    "        # 출력층에서의 오차 (δ_k)\n",
    "        delta_o = (o - t) * sigmoid_derivative(self.o_sum)  # δ_k = (o_k - t_k) * τ'(o_sum_k)\n",
    "        \n",
    "        # 은닉층에서의 오차 (δ_j)\n",
    "        delta_z = np.dot(delta_o, self.v.T) * sigmoid_derivative(self.z_sum)  # δ_j = (Σ δ_k * v_jk) * τ'(z_sum_j)\n",
    "        \n",
    "        # 가중치 v와 바이어스 b_v 업데이트\n",
    "        v_grad = np.dot(z.T, delta_o)  # ∂E/∂v = z * δ_k\n",
    "        self.v -= self.learning_rate * v_grad  # v -= η * ∂E/∂v\n",
    "        self.b_v -= self.learning_rate * np.sum(delta_o, axis=0, keepdims=True)  # b_v -= η * δ_k\n",
    "        \n",
    "        # 가중치 u와 바이어스 b_u 업데이트\n",
    "        u_grad = np.dot(x.T, delta_z)  # ∂E/∂u = x * δ_j\n",
    "        self.u -= self.learning_rate * u_grad  # u -= η * ∂E/∂u\n",
    "        self.b_u -= self.learning_rate * np.sum(delta_z, axis=0, keepdims=True)  # b_u -= η * δ_j\n",
    "\n",
    "    def train(self, X, T, epochs=1000, stop_condition=1e-4):\n",
    "        \"\"\"\n",
    "        MLP 학습\n",
    "        :param X: 훈련 데이터 (N, input_size)\n",
    "        :param T: 타겟 데이터 (N, output_size)\n",
    "        :param epochs: 최대 반복 횟수\n",
    "        :param stop_condition: 종료 조건 (오차 임계값)\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            total_error = 0\n",
    "            for i in range(len(X)):\n",
    "                # 순전파\n",
    "                x = X[i:i+1]  # (1, input_size)\n",
    "                t = T[i:i+1]  # (1, output_size)\n",
    "                z, o = self.forward(x)\n",
    "                \n",
    "                # 손실 계산 (평균 제곱 오차)\n",
    "                error = 0.5 * np.sum((o - t) ** 2)\n",
    "                total_error += error\n",
    "                \n",
    "                # 역전파\n",
    "                self.backward(x, t, z, o)\n",
    "            \n",
    "            # 평균 오차 출력\n",
    "            avg_error = total_error / len(X)\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Average Error: {avg_error}\")\n",
    "            \n",
    "            # 종료 조건 확인\n",
    "            if avg_error < stop_condition:\n",
    "                print(f\"종료 조건 만족 (오차 < {stop_condition})\")\n",
    "                break\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        예측\n",
    "        :param x: 입력 데이터\n",
    "        :return: 예측값\n",
    "        \"\"\"\n",
    "        _, o = self.forward(x)\n",
    "        return o\n",
    "\n",
    "# 테스트  \n",
    "if __name__ == \"__main__\":\n",
    "    # XOR 문제 데이터\n",
    "    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # 입력\n",
    "    T = np.array([[0], [1], [1], [0]])  # 타겟 (XOR)\n",
    "    \n",
    "    # MLP 초기화 (입력층: 2, 은닉층: 4, 출력층: 1)\n",
    "    mlp = MLP(input_size=2, hidden_size=4, output_size=1, learning_rate=0.1)\n",
    "    \n",
    "    # 학습\n",
    "    mlp.train(X, T, epochs=10000, stop_condition=1e-3)\n",
    "    \n",
    "    # 예측\n",
    "    print(\"\\n예측 결과:\")\n",
    "    for i in range(len(X)):\n",
    "        x = X[i:i+1]\n",
    "        pred = mlp.predict(x)\n",
    "        print(f\"입력: {X[i]}, 타겟: {T[i]}, 예측: {pred[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
