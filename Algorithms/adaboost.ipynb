{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분류기 1: alpha=11.5129, epsilon=0.0000\n",
      "분류기 2: alpha=11.5129, epsilon=0.0000\n",
      "분류기 3: alpha=11.5129, epsilon=0.0000\n",
      "분류기 4: alpha=11.5129, epsilon=0.0000\n",
      "분류기 5: alpha=11.5129, epsilon=0.0000\n",
      "\n",
      "예측 결과:\n",
      "입력: [1 2], 실제: -1, 예측: 1.0\n",
      "입력: [2 3], 실제: -1, 예측: 1.0\n",
      "입력: [3 1], 실제: -1, 예측: 1.0\n",
      "입력: [4 3], 실제: -1, 예측: 1.0\n",
      "입력: [5 5], 실제: 1, 예측: 1.0\n",
      "입력: [6 4], 실제: 1, 예측: -1.0\n",
      "입력: [7 6], 실제: 1, 예측: -1.0\n",
      "입력: [8 5], 실제: 1, 예측: -1.0\n",
      "\n",
      "정확도: 12.50%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionStump:\n",
    "    \"\"\"\n",
    "    약한 학습기로 사용할 결정 스텀프\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.polarity = 1  # 1: x <= threshold, -1: x > threshold\n",
    "        self.alpha = None\n",
    "\n",
    "    def fit(self, X, y, weights):\n",
    "        \"\"\"\n",
    "        결정 스텀프 학습\n",
    "        :param X: 입력 데이터 (N, d)\n",
    "        :param y: 타겟 값 (N,)\n",
    "        :param weights: 샘플 가중치 (N,)\n",
    "        \"\"\"\n",
    "        N, d = X.shape\n",
    "        min_error = float('inf')\n",
    "\n",
    "        # 모든 특성과 임계값에 대해 테스트\n",
    "        for feature in range(d):\n",
    "            X_feature = X[:, feature]\n",
    "            thresholds = np.unique(X_feature)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                for polarity in [1, -1]:\n",
    "                    error = 0\n",
    "                    # 예측\n",
    "                    for i in range(N):\n",
    "                        pred = 1 if polarity * X_feature[i] <= polarity * threshold else -1\n",
    "                        if pred != y[i]:\n",
    "                            error += weights[i]\n",
    "\n",
    "                    # 최소 오차 갱신\n",
    "                    if error < min_error:\n",
    "                        min_error = error\n",
    "                        self.feature_idx = feature\n",
    "                        self.threshold = threshold\n",
    "                        self.polarity = polarity\n",
    "\n",
    "        return min_error\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        결정 스텀프 예측\n",
    "        :param X: 입력 데이터 (N, d)\n",
    "        :return: 예측값 (N,)\n",
    "        \"\"\"\n",
    "        X_feature = X[:, self.feature_idx]\n",
    "        predictions = np.ones(len(X))\n",
    "        if self.polarity == 1:\n",
    "            predictions[X_feature <= self.threshold] = -1\n",
    "        else:\n",
    "            predictions[X_feature > self.threshold] = -1\n",
    "        return predictions\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self, n_classifiers=5):\n",
    "        \"\"\"\n",
    "        AdaBoost 초기화\n",
    "        :param n_classifiers: 약한 학습기 개수 (K)\n",
    "        \"\"\"\n",
    "        self.n_classifiers = n_classifiers\n",
    "        self.classifiers = []\n",
    "        self.alphas = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        AdaBoost 학습\n",
    "        :param X: 훈련 데이터 (N, d)\n",
    "        :param y: 타겟 값 (N,) {-1, 1}\n",
    "        \"\"\"\n",
    "        N = len(X)\n",
    "        # 샘플 가중치 초기화 (w_i = 1/N)\n",
    "        weights = np.ones(N) / N\n",
    "\n",
    "        for k in range(self.n_classifiers):\n",
    "            # 약한 학습기 학습\n",
    "            clf = DecisionStump()\n",
    "            error = clf.fit(X, y, weights)\n",
    "\n",
    "            # 오차 계산\n",
    "            epsilon = error\n",
    "            if epsilon > 0.5:\n",
    "                print(f\"오차가 0.5보다 큼 (epsilon={epsilon}), 학습 중단\")\n",
    "                break\n",
    "\n",
    "            # alpha_k 계산\n",
    "            alpha = 0.5 * np.log((1 - epsilon) / (epsilon + 1e-10))\n",
    "            self.alphas.append(alpha)\n",
    "            clf.alpha = alpha\n",
    "\n",
    "            # 예측\n",
    "            predictions = clf.predict(X)\n",
    "\n",
    "            # 가중치 업데이트\n",
    "            for i in range(N):\n",
    "                if predictions[i] != y[i]:  # 잘못 분류된 경우\n",
    "                    weights[i] *= np.exp(alpha)\n",
    "                else:  # 맞춘 경우\n",
    "                    weights[i] *= np.exp(-alpha)\n",
    "\n",
    "            # 가중치 정규화\n",
    "            weights /= np.sum(weights)\n",
    "\n",
    "            # 분류기 추가\n",
    "            self.classifiers.append(clf)\n",
    "            print(f\"분류기 {k+1}: alpha={alpha:.4f}, epsilon={epsilon:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        AdaBoost 예측\n",
    "        :param X: 입력 데이터 (N, d)\n",
    "        :return: 예측값 (N,)\n",
    "        \"\"\"\n",
    "        clf_preds = np.zeros(len(X))\n",
    "        for alpha, clf in zip(self.alphas, self.classifiers):\n",
    "            clf_preds += alpha * clf.predict(X)\n",
    "        return np.sign(clf_preds)\n",
    "\n",
    "# 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 간단한 이진 분류 데이터 생성\n",
    "    np.random.seed(0)\n",
    "    X = np.array([\n",
    "        [1, 2], [2, 3], [3, 1], [4, 3],  # 클래스 -1\n",
    "        [5, 5], [6, 4], [7, 6], [8, 5]   # 클래스 1\n",
    "    ])\n",
    "    y = np.array([-1, -1, -1, -1, 1, 1, 1, 1])\n",
    "\n",
    "    # AdaBoost 학습\n",
    "    adaboost = AdaBoost(n_classifiers=5)\n",
    "    adaboost.fit(X, y)\n",
    "\n",
    "    # 예측\n",
    "    predictions = adaboost.predict(X)\n",
    "    print(\"\\n예측 결과:\")\n",
    "    for i in range(len(X)):\n",
    "        print(f\"입력: {X[i]}, 실제: {y[i]}, 예측: {predictions[i]}\")\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    print(f\"\\n정확도: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
